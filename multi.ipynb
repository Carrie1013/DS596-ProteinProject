{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/qiaochufeng/Documents/GitHub/DS596-Project/protein_bert\n"
     ]
    }
   ],
   "source": [
    "%cd protein_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4. 512-maxlen\n"
     ]
    }
   ],
   "source": [
    "# Model's hyperparameters\n",
    "BATCH_SIZE = 1\n",
    "ACCUM_BATCH = 32\n",
    "MAX_PROTEIN_STR_LEN = 512\n",
    "ENCODER_LR = 5e-6\n",
    "GENERAL_LR = 3e-05\n",
    "N_FROZEN_EPOCH = 1\n",
    "GRADIENT_CHECKPOINT = False # True if RAM < 16GB\n",
    "SEED = 43\n",
    "\n",
    "# File's hyperparameters\n",
    "FILE_DIR = \"/protein_benchmarks/fluorescence.train.csv\" \n",
    "COL_NAMES = ['seq','label'] # optional, but no need\n",
    "\n",
    "# Trainer's hyperparameters\n",
    "CPU_WORKERS = 2\n",
    "N_CHECKPOINTS = 1 # number of top-k models you want to save\n",
    "MONITOR_METRIC = \"val_loss\"\n",
    "MONITOR_MODE = \"min\"\n",
    "MIN_EPOCHS = 1\n",
    "MAX_EPOCHS = 7 # Increase to 10-20 epochs to maximize accuracy (needs more GPU hours on Kaggle)\n",
    "PATIENCE = MAX_EPOCHS\n",
    "NUM_GPU = 0\n",
    "PRECISION = 32\n",
    "AMP_BACKEND = \"native\"\n",
    "\n",
    "wandb_flag=True # Need a free wandb.ai account (retrieve a personal key there)\n",
    "wandb_name=\"Run 4. %d-maxlen\" % MAX_PROTEIN_STR_LEN\n",
    "wandb_project=\"ProtBERT DeepLoc\"\n",
    "\n",
    "print(wandb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: protein-bert in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/protein_bert-1.0.1-py3.9.egg (1.0.1)\n",
      "Collecting pyfastx\n",
      "  Downloading pyfastx-2.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from protein-bert) (2.17.0)\n",
      "Requirement already satisfied: tensorflow_addons in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/tensorflow_addons-0.23.0-py3.9-macosx-11.0-arm64.egg (from protein-bert) (0.23.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from protein-bert) (1.24.4)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from protein-bert) (2.0.3)\n",
      "Requirement already satisfied: h5py in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from protein-bert) (3.11.0)\n",
      "Requirement already satisfied: lxml in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from protein-bert) (4.9.3)\n",
      "Requirement already satisfied: pyfaidx in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/pyfaidx-0.8.1.3-py3.9.egg (from protein-bert) (0.8.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from pandas->protein-bert) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from pandas->protein-bert) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from pandas->protein-bert) (2023.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from pyfaidx->protein-bert) (6.8.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from pyfaidx->protein-bert) (23.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (1.51.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorflow->protein-bert) (0.37.1)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/typeguard-2.13.3-py3.9.egg (from tensorflow_addons->protein-bert) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->protein-bert) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow->protein-bert) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow->protein-bert) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow->protein-bert) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->protein-bert) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->protein-bert) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->protein-bert) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->protein-bert) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow->protein-bert) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow->protein-bert) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow->protein-bert) (2.3.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from importlib-metadata->pyfaidx->protein-bert) (3.16.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->protein-bert) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow->protein-bert) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow->protein-bert) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->protein-bert) (0.1.0)\n",
      "Downloading pyfastx-2.1.0-cp39-cp39-macosx_11_0_arm64.whl (722 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.9/722.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyfastx\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pyfastx-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install protein-bert pyfastx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfastx\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGVGDATYGKLALKFI...</td>\n",
       "      <td>3.713898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.577288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKGEGLFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.677451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.551528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.718230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq     label\n",
       "0  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGVGDATYGKLALKFI...  3.713898\n",
       "1  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.577288\n",
       "2  SKGEGLFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.677451\n",
       "3  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.551528\n",
       "4  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.718230"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_file_path = './protein_bert/protein_benchmarks/fluorescence.valid.csv'\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set = train_test_split(train_set, test_size = 0.2, random_state = 0)\n",
    "UNIQUE_LABELS = train_set['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024_11_11-13:20:06] Training set: Filtered out 0 of 3088 (0.0%) records of lengths exceeding 510.\n",
      "[2024_11_11-13:20:06] Validation set: Filtered out 0 of 772 (0.0%) records of lengths exceeding 510.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3.436640977859497",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m model_generator \u001b[38;5;241m=\u001b[39m FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     10\u001b[0m         get_model_with_hidden_layers_as_outputs, dropout_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     12\u001b[0m training_callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m, min_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-05\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     14\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     15\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_SPEC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs_per_stage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-04\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin_with_frozen_pretrained_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_with_frozen_pretrained_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_final_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_seq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_lr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/protein_bert-1.0.1-py3.9.egg/proteinbert/finetuning.py:48\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m(model_generator, input_encoder, output_spec, train_seqs, train_raw_Y, valid_seqs, valid_raw_Y, seq_len, batch_size, max_epochs_per_stage, lr, begin_with_frozen_pretrained_layers, lr_with_frozen_pretrained_layers, n_final_epochs, final_seq_len, final_lr, callbacks)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinetune\u001b[39m(model_generator, input_encoder, output_spec, train_seqs, train_raw_Y, valid_seqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, valid_raw_Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, \\\n\u001b[1;32m     45\u001b[0m         max_epochs_per_stage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, begin_with_frozen_pretrained_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, lr_with_frozen_pretrained_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, n_final_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \\\n\u001b[1;32m     46\u001b[0m         final_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m, final_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, callbacks \u001b[38;5;241m=\u001b[39m []):\n\u001b[0;32m---> 48\u001b[0m     encoded_train_set, encoded_valid_set \u001b[38;5;241m=\u001b[39m \u001b[43mencode_train_and_valid_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_raw_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_raw_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m begin_with_frozen_pretrained_layers:\n\u001b[1;32m     51\u001b[0m         log(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining with frozen pretrained layers...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/protein_bert-1.0.1-py3.9.egg/proteinbert/finetuning.py:161\u001b[0m, in \u001b[0;36mencode_train_and_valid_sets\u001b[0;34m(train_seqs, train_raw_Y, valid_seqs, valid_raw_Y, input_encoder, output_spec, seq_len)\u001b[0m\n\u001b[1;32m    159\u001b[0m     encoded_valid_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     encoded_valid_set \u001b[38;5;241m=\u001b[39m \u001b[43mencode_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_raw_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_filtering\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidation set\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_train_set, encoded_valid_set\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/protein_bert-1.0.1-py3.9.egg/proteinbert/finetuning.py:175\u001b[0m, in \u001b[0;36mencode_dataset\u001b[0;34m(seqs, raw_Y, input_encoder, output_spec, seq_len, needs_filtering, dataset_name, verbose)\u001b[0m\n\u001b[1;32m    172\u001b[0m     raw_Y \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_Y\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    174\u001b[0m X \u001b[38;5;241m=\u001b[39m input_encoder\u001b[38;5;241m.\u001b[39mencode_X(seqs, seq_len)\n\u001b[0;32m--> 175\u001b[0m Y, sample_weigths \u001b[38;5;241m=\u001b[39m \u001b[43mencode_Y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, Y, sample_weigths\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/protein_bert-1.0.1-py3.9.egg/proteinbert/finetuning.py:182\u001b[0m, in \u001b[0;36mencode_Y\u001b[0;34m(raw_Y, output_spec, seq_len)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encode_seq_Y(raw_Y, seq_len, output_spec\u001b[38;5;241m.\u001b[39moutput_type\u001b[38;5;241m.\u001b[39mis_binary, output_spec\u001b[38;5;241m.\u001b[39munique_labels)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output_spec\u001b[38;5;241m.\u001b[39moutput_type\u001b[38;5;241m.\u001b[39mis_categorical:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_categorical_Y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(raw_Y))\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output_spec\u001b[38;5;241m.\u001b[39moutput_type\u001b[38;5;241m.\u001b[39mis_numeric \u001b[38;5;129;01mor\u001b[39;00m output_spec\u001b[38;5;241m.\u001b[39moutput_type\u001b[38;5;241m.\u001b[39mis_binary:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m raw_Y\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m), np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(raw_Y))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/protein_bert-1.0.1-py3.9.egg/proteinbert/finetuning.py:215\u001b[0m, in \u001b[0;36mencode_categorical_Y\u001b[0;34m(labels, unique_labels)\u001b[0m\n\u001b[1;32m    212\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(labels), dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels):\n\u001b[0;32m--> 215\u001b[0m     Y[i] \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "\u001b[0;31mKeyError\u001b[0m: 3.436640977859497"
     ]
    }
   ],
   "source": [
    "OUTPUT_TYPE = OutputType(is_seq = False, output_type = 'categorical')\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model(\n",
    "    local_model_dump_dir = './',\n",
    "    local_model_dump_file_name = 'epoch_2_sample.pkl'\n",
    ")\n",
    "\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "        seq_len = 512, batch_size = 32, max_epochs_per_stage = 2, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cq1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
